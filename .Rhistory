<<<<<<< HEAD
inside <- (j*pi*x)
prod(sqrt(2),cos(inside))
}
X*sqrt(2)
cosine_basis(1, X)
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)
}
cosine_basis(1, X)
1*pi
1*pi*X
cos(1*pi*X)
cos(1*pi*X, digits=3))
cos(1*pi*X, digits=3)
cos(1*pi*X)
cos(X)
cos(1*X)
cos(pi*X)
cos(2*pi*X)
cos(3*pi*X)
cos(4*pi*X)
cos(5*pi*X)
pi*X
glmFit <- glm(Y ~ x0, family=gaussian(link="identity"))
k    <- 3
kfCV <- cv.glm(data=dfRegr, glmfit=glmFit, K=k)
?cv.glm
library(boot)
?cv.glm
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)
}
pi*X
cos(X)
cos(pi*X)
plot(X, cos(pi*X))
cosine_basis(1, Xnew)
## Function to compute the cosine basis
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)*sqrt(2)
}
cosine_basis(1, Xnew)
x1 <- cosine_basis(1, Xnew)
x1
plot(Xnew, x1)
# Get the rest of the covariates
x1 <- cosine_basis(1, Xnew)
x2 <- cosine_basis(2, Xnew)
x3 <- cosine_basis(3, Xnew)
x4 <- cosine_basis(4, Xnew)
x5 <- cosine_basis(5, Xnew)
x6 <- cosine_basis(6, Xnew)
x6
x5
plot(Xnew, x5)
plot(Xnew, x6)
plot(Xnew, x2)
plot(Xnew, x3)
plot(Xnew, x0)
for(i in 1:6){print(i)}
plot(Xnew, Y)
mod0 <- glm(Y ~ x0, family=gaussian(link="identity"))
mod0 <- glm(Y ~ x0, family=gaussian(link="identity"))
data(ufcwc)
Y = ufcwc$Height
X = ufcwc$Dbh
n = length(Xnew)
Xnew <- (X-min(X))/(max(X)-min(X))
x0 <- rep(1, n)
## Function to compute the cosine basis
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)*sqrt(2)
}
# Get the rest of the covariates
x1 <- cosine_basis(1, Xnew)
x2 <- cosine_basis(2, Xnew)
x3 <- cosine_basis(3, Xnew)
x4 <- cosine_basis(4, Xnew)
x5 <- cosine_basis(5, Xnew)
x6 <- cosine_basis(6, Xnew)
## Cost Function
cost = function(y, predy){
err = mean( (y-predy)^2 )
return(err)
}
## Get the fits
mod0 <- glm(Y ~ x0, family=gaussian(link="identity"))
mod1 <- glm(Y ~ x0+x1, family=gaussian(link="identity"))
mod2 <- glm(Y ~ x0+x1+x2, family=gaussian(link="identity"))
mod3 <- glm(Y ~ x0+x1+x3, family=gaussian(link="identity"))
mod4 <- glm(Y ~ x0+x1+x3+x4, family=gaussian(link="identity"))
mod5 <- glm(Y ~ x0+x1+x3+x4+x5, family=gaussian(link="identity"))
mod6 <- glm(Y ~ x0+x1+x3+x4+x5+x6, family=gaussian(link="identity"))
points(Xnew, fitted(mod6))
points(Xnew, fitted(mod6), type="l")
?cv.glm
kfCV <- cv.glm(data=ufcwc, cost=cost, glmfit=glmFit, K=k)
cbind(ufcwc, x0, x1)
ufcwc <- cbind(ufcwc, x0, x1, x2, x3, x4, x5, x6)
data(ufcwc)
Y = ufcwc$Height
X = ufcwc$Dbh
n = length(Xnew)
Xnew <- (X-min(X))/(max(X)-min(X))
x0 <- rep(1, n)
## Function to compute the cosine basis
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)*sqrt(2)
}
# Get the rest of the covariates
x1 <- cosine_basis(1, Xnew)
x2 <- cosine_basis(2, Xnew)
x3 <- cosine_basis(3, Xnew)
x4 <- cosine_basis(4, Xnew)
x5 <- cosine_basis(5, Xnew)
x6 <- cosine_basis(6, Xnew)
ufcwc <- cbind(ufcwc, x0, x1, x2, x3, x4, x5, x6)
## Cost Function
cost = function(y, predy){
err = mean( (y-predy)^2 )
return(err)
}
## Get the fits
mod0 <- glm(Height ~ x0, family=gaussian(link="identity"), data=ufcwc)
mod1 <- glm(Height ~ x0+x1, family=gaussian(link="identity"), data=ufcwc)
mod2 <- glm(Height ~ x0+x1+x2, family=gaussian(link="identity"), data=ufcwc)
mod3 <- glm(Height ~ x0+x1+x3, family=gaussian(link="identity"), data=ufcwc)
mod4 <- glm(Height ~ x0+x1+x3+x4, family=gaussian(link="identity"), data=ufcwc)
mod5 <- glm(Height ~ x0+x1+x3+x4+x5, family=gaussian(link="identity"), data=ufcwc)
mod6 <- glm(Height ~ x0+x1+x3+x4+x5+x6, family=gaussian(link="identity"), data=ufcwc)
kfCV <- cv.glm(data=ufcwc, cost=cost, glmfit=mod0, K=4)
names(ufcwc)
data(ufcwc)
Y = ufcwc$Height
X = ufcwc$Dbh
n = length(Xnew)
Xnew <- (X-min(X))/(max(X)-min(X))
x0 <- rep(1, n)
## Function to compute the cosine basis
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)*sqrt(2)
}
# Get the rest of the covariates
x1 <- cosine_basis(1, Xnew)
x2 <- cosine_basis(2, Xnew)
x3 <- cosine_basis(3, Xnew)
x4 <- cosine_basis(4, Xnew)
x5 <- cosine_basis(5, Xnew)
x6 <- cosine_basis(6, Xnew)
ufcwc <- cbind(ufcwc, x0, x1, x2, x3, x4, x5, x6)
## Cost Function
cost = function(y, predy){
err = mean( (y-predy)^2 )
return(err)
}
## Get the fits
mod0 <- glm(Height ~ x0, family=gaussian(link="identity"), data=ufcwc)
mod1 <- glm(Height ~ x0+x1, family=gaussian(link="identity"), data=ufcwc)
mod2 <- glm(Height ~ x0+x1+x2, family=gaussian(link="identity"), data=ufcwc)
mod3 <- glm(Height ~ x0+x1+x3, family=gaussian(link="identity"), data=ufcwc)
mod4 <- glm(Height ~ x0+x1+x3+x4, family=gaussian(link="identity"), data=ufcwc)
mod5 <- glm(Height ~ x0+x1+x3+x4+x5, family=gaussian(link="identity"), data=ufcwc)
mod6 <- glm(Height ~ x0+x1+x3+x4+x5+x6, family=gaussian(link="identity"), data=ufcwc)
ufcwc
data(ufcwc)
library(alr3)
data(ufcwc)
Y = ufcwc$Height
X = ufcwc$Dbh
n = length(Xnew)
Xnew <- (X-min(X))/(max(X)-min(X))
x0 <- rep(1, n)
## Function to compute the cosine basis
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)*sqrt(2)
}
# Get the rest of the covariates
x1 <- cosine_basis(1, Xnew)
x2 <- cosine_basis(2, Xnew)
x3 <- cosine_basis(3, Xnew)
x4 <- cosine_basis(4, Xnew)
x5 <- cosine_basis(5, Xnew)
x6 <- cosine_basis(6, Xnew)
ufcwc <- cbind(ufcwc, x0, x1, x2, x3, x4, x5, x6)
## Cost Function
cost = function(y, predy){
err = mean( (y-predy)^2 )
return(err)
}
## Get the fits
mod0 <- glm(Height ~ x0, family=gaussian(link="identity"), data=ufcwc)
mod1 <- glm(Height ~ x0+x1, family=gaussian(link="identity"), data=ufcwc)
mod2 <- glm(Height ~ x0+x1+x2, family=gaussian(link="identity"), data=ufcwc)
mod3 <- glm(Height ~ x0+x1+x3, family=gaussian(link="identity"), data=ufcwc)
mod4 <- glm(Height ~ x0+x1+x3+x4, family=gaussian(link="identity"), data=ufcwc)
mod5 <- glm(Height ~ x0+x1+x3+x4+x5, family=gaussian(link="identity"), data=ufcwc)
mod6 <- glm(Height ~ x0+x1+x3+x4+x5+x6, family=gaussian(link="identity"), data=ufcwc)
cv.glm(data=ufcwc, cost=cost, glmfit=mod0, K=4)
cv.glm(data=ufcwc, mod0, cost=cost, K=4)
names(cv.glm(data=ufcwc, mod0, cost=cost, K=4))
cv.glm(data=ufcwc, mod0, cost=cost, K=4)$delta
cv.glm(data=ufcwc, mod0, cost=cost, K=4)$K
j=1
modj
rm(f)
rm()
rm(j)
cv.glm(data=ufcwc, mod0, cost=cost, K=3)
mod0_fit <- cv.glm(data=ufcwc, mod0, cost=cost, K=3)$delta[1]
mod0_fit <- cv.glm(data=ufcwc, mod0, cost=cost, K=3)$delta[1]## Order Results
mod0_fit <- cv.glm(data=ufcwc, mod0, cost=cost, K=3)$delta[1]
mod1_fit <- cv.glm(data=ufcwc, mod1, cost=cost, K=3)$delta[1]
mod2_fit <- cv.glm(data=ufcwc, mod2, cost=cost, K=3)$delta[1]
mod3_fit <- cv.glm(data=ufcwc, mod3, cost=cost, K=3)$delta[1]
mod4_fit <- cv.glm(data=ufcwc, mod4, cost=cost, K=3)$delta[1]
mod5_fit <- cv.glm(data=ufcwc, mod5, cost=cost, K=3)$delta[1]
mod6_fit <- cv.glm(data=ufcwc, mod6, cost=cost, K=3)$delta[1]
scores <- c(mod0_fit, mod1_fit, mod2_fit, mod3_fit, mod4_fit, mod5_fit, mod6_fit, mod7_fit)
scores <- c(mod0_fit, mod1_fit, mod2_fit, mod3_fit, mod4_fit, mod5_fit, mod6_fit)
scores
plot(scores)
min(scores)
foo = order(Xnew)
x_ord <- X[foo]
y_ord <- Y[foo]
data(ufcwc)
Y = ufcwc$Height
X = ufcwc$Dbh
n = length(Xnew)
Xnew <- (X-min(X))/(max(X)-min(X))
x0 <- rep(1, n)
## Function to compute the cosine basis
cosine_basis <- function(j,x){
inside <- (j*pi*x)
cos(inside)*sqrt(2)
=======
<<<<<<< HEAD
y_ord2 <- Y[ord]
points(x_ord2, exp(fitted(log_fit))[ord], type="l")
log_fit <- lm(Height ~ log(Dbh), data=ufcwc)
plot(X, Y)
ord <- order(X)
x_ord2 <- X[ord]
log_fitted <- exp(fitted(log_fit))
y_ord2 <- Y[ord]
points(x_ord2, exp(fitted(log_fit))[ord], type="l")
log_fit <- lm(log(Height) ~ log(Dbh), data=ufcwc)
plot(X, Y)
ord <- order(X)
log_fitted <- exp(fitted(log_fit))
x_ord2 <- X[ord]
y_ord2 <- Y[ord]
points(x_ord2, exp(fitted(log_fit))[ord], type="l")
weeks_t <- c(.95, .95, .95, .95, .03, .03, .03, .03, .02, .02, .02, .02)
e_w <- c(.001, .001, .999, .999, .02, .02, .98, .98, .04, .04, .96, .96)
r_e <- c(.9, .1, .2, .8, .9, .1, .2, .8, .9, .1, .2, .8)
probs2 <- cbind(weeks_t, e_w, r_e)
row.names(probs2) <- NULL
R <- apply(probs2, 1, prod)
condensed <- c(sum(R[1], R[3]), sum(R[2], R[4]), sum(R[5], R[7]),
sum(R[6], R[8]),sum(R[9], R[11]), sum(R[10], R[12]))
dist_true <- condensed[c(1, 3, 5)]/sum(condensed[c(1, 3, 5)])
dist_false <- condensed[c(2, 4, 6)]/sum(condensed[c(2, 4, 6)])
exp_false <- 1*dist_false[2] + 2*dist_false[3]
dist_true
probs2
R
######## Part 1 ###########
library(xtable)
wt = c(.95, .95, .95, .95)
e = c(.001,.001,.999,.999)
sp = c(.1, .9, .1, .9)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs <- cbind(wt, e, sp, ap, r)
xtable(probs, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
xtable(probs)
wt = c(.02, .02, .02, .02)
e = c(.04,.04,.96,.96)
sp = c(.2, .8, .2, .8)
wt = c(.02, .02, .02, .02)
e = c(.04,.04,.96,.96)
sp = c(.2, .8, .2, .8)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs <- cbind(wt, e, sp, ap, r)
xtable(probs, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
probs_week2 <- cbind(wt, e, sp, ap, r)
wt = c(.02, .02, .02, .02)
e = c(.04,.04,.96,.96)
sp = c(.2, .8, .2, .8)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs_week2 <- cbind(wt, e, sp, ap, r)
xtable(probs_week2, digits=3)
wt = c(.02, .02, .02, .02)
e = c(.04,.04,.96,.96)
sp = c(.2, .8, .2, .8)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs_week2 <- cbind(wt, e, sp, ap, r)
xtable(probs_week2, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
######## Part 1 ###########
library(xtable)
wt = c(.95, .95, .95, .95)
e = c(.001,.001,.999,.999)
sp = c(.1, .9, .1, .9)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs <- cbind(wt, e, sp, ap, r)
xtable(probs, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
### WEEKS = 2 ###
wt = c(.02, .02, .02, .02)
e = c(.04,.04,.96,.96)
sp = c(.2, .8, .2, .8)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs_week2 <- cbind(wt, e, sp, ap, r)
xtable(probs_week2, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
xtable(dist_trye)
xtable(dist_true)
xtable(cbind(c("0", "1", "2")), dist_true)
names = c("Weeks = 2", "Weeks = 1", "Weeks = 2")
cbind(names, dist_true)
rbind(names, dist_true)
dist_true <- condensed[c(1, 3, 5)]/sum(condensed[c(1, 3, 5)])
names = c(0, 1, 2)
cbind(names, dist_true)
rbind(names, dist_true)
dist_true <- condensed[c(1, 3, 5)]/sum(condensed[c(1, 3, 5)])
weeks = c(0, 1, 2)
rbind(weeks, dist_true)
xtable(res, digits=2)
res <- rbind(weeks, dist_true)
xtable(res, digits=2)
xtable(res, digits=3)
weeks_t <- c(.95, .95, .95, .95, .03, .03, .03, .03, .02, .02, .02, .02)
e_w <- c(.001, .001, .999, .999, .02, .02, .98, .98, .04, .04, .96, .96)
r_e <- c(.9, .1, .2, .8, .9, .1, .2, .8, .9, .1, .2, .8)
probs2 <- cbind(weeks_t, e_w, r_e)
row.names(probs2) <- NULL
R <- apply(probs2, 1, prod)
condensed <- c(sum(R[1], R[3]), sum(R[2], R[4]), sum(R[5], R[7]),
sum(R[6], R[8]),sum(R[9], R[11]), sum(R[10], R[12]))
dist_true <- condensed[c(1, 3, 5)]/sum(condensed[c(1, 3, 5)])
weeks = c(0, 1, 2)
res <- rbind(weeks, dist_true)
xtable(res, digits=2)
dist_false <- condensed[c(2, 4, 6)]/sum(condensed[c(2, 4, 6)])
dist_false
exp_false <- 1*dist_false[2] + 2*dist_false[3]
exp_false
######## Part 3 ###########
weeks_t <- c(.95, .95, .95, .95, .03, .03, .03, .03, .02, .02, .02, .02)
e_w <- c(.001, .001, .999, .999, .02, .02, .98, .98, .04, .04, .96, .96)
r_e <- c(.9, .1, .2, .8, .9, .1, .2, .8, .9, .1, .2, .8)
probs2 <- cbind(weeks_t, e_w, r_e)
row.names(probs2) <- NULL
R <- apply(probs2, 1, prod)
condensed <- c(sum(R[1], R[3]), sum(R[2], R[4]), sum(R[5], R[7]),
sum(R[6], R[8]),sum(R[9], R[11]), sum(R[10], R[12]))
dist_true <- condensed[c(1, 3, 5)]/sum(condensed[c(1, 3, 5)])
weeks = c(0, 1, 2)
res <- rbind(weeks, dist_true)
xtable(res, digits=2)
dist_false <- condensed[c(2, 4, 6)]/sum(condensed[c(2, 4, 6)])
exp_false <- 1*dist_false[2] + 2*dist_false[3]
dist_true
######## Part 1 ###########
library(xtable)
wt = c(.95, .95, .95, .95)
e = c(.001,.001,.999,.999)
sp = c(.1, .9, .1, .9)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs <- cbind(wt, e, sp, ap, r)
xtable(probs, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
######## Part 1 ###########
library(xtable)
wt = c(.95, .95, .95, .95)
e = c(.001,.001,.999,.999)
sp = c(.1, .9, .1, .9)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs <- cbind(wt, e, sp, ap, r)
xtable(probs, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
######## Part 1 ###########
library(xtable)
wt = c(.95, .95, .95, .95)
e = c(.001,.001,.999,.999)
sp = c(.1, .9, .1, .9)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs <- cbind(wt, e, sp, ap, r)
xtable(probs, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
probs
wt = c(.02, .02, .02, .02)
e = c(.04,.04,.96,.96)
sp = c(.2, .8, .2, .8)
ap = c(.99, .95, .95, .01)
r = c(.9, .9, .2, .2)
probs_week2 <- cbind(wt, e, sp, ap, r)
xtable(probs_week2, digits=3)
r1=prod(wt[1], e[1], sp[1], ap[1], r[1])
r2=prod(wt[2], e[2], sp[2], ap[2], r[1])
r3=prod(wt[3], e[3], sp[3], ap[3], r[3])
r4=prod(wt[4], e[4], sp[4], ap[4], r[4])
sum(r1, r2)/sum(r1, r2, r3, r4)
sum(r3, r4)/sum(r1, r2, r3, r4)
######## Part 3 ###########
weeks_t <- c(.95, .95, .95, .95, .03, .03, .03, .03, .02, .02, .02, .02)
e_w <- c(.001, .001, .999, .999, .02, .02, .98, .98, .04, .04, .96, .96)
r_e <- c(.9, .1, .2, .8, .9, .1, .2, .8, .9, .1, .2, .8)
probs2 <- cbind(weeks_t, e_w, r_e)
row.names(probs2) <- NULL
R <- apply(probs2, 1, prod)
condensed <- c(sum(R[1], R[3]), sum(R[2], R[4]), sum(R[5], R[7]),
sum(R[6], R[8]),sum(R[9], R[11]), sum(R[10], R[12]))
dist_true <- condensed[c(1, 3, 5)]/sum(condensed[c(1, 3, 5)])
weeks = c(0, 1, 2)
res <- rbind(weeks, dist_true)
xtable(res, digits=2)
dist_false <- condensed[c(2, 4, 6)]/sum(condensed[c(2, 4, 6)])
exp_false <- 1*dist_false[2] + 2*dist_false[3]
dist_true
exp_false
=======
abline(v=results_2013[results_2013$team == name, "wins"], col="red")
abline(v=results_2013[results_2013$team == name, "lower"], col="blue")
abline(v=results_2013[results_2013$team == name, "upper"], col="blue")
>>>>>>> 7f763f76725fb85f2dbe3f0e30b27aae3d6208b0
}
# Get the rest of the covariates
x1 <- cosine_basis(1, Xnew)
x2 <- cosine_basis(2, Xnew)
x3 <- cosine_basis(3, Xnew)
x4 <- cosine_basis(4, Xnew)
x5 <- cosine_basis(5, Xnew)
x6 <- cosine_basis(6, Xnew)
ufcwc <- cbind(ufcwc, x0, x1, x2, x3, x4, x5, x6)
## Cost Function
cost = function(y, predy){
err = mean( (y-predy)^2 )
return(err)
}
## Get the fits
mod0 <- glm(Height ~ x0, family=gaussian(link="identity"), data=ufcwc)
mod1 <- glm(Height ~ x0+x1, family=gaussian(link="identity"), data=ufcwc)
mod2 <- glm(Height ~ x0+x1+x2, family=gaussian(link="identity"), data=ufcwc)
mod3 <- glm(Height ~ x0+x1+x3, family=gaussian(link="identity"), data=ufcwc)
mod4 <- glm(Height ~ x0+x1+x3+x4, family=gaussian(link="identity"), data=ufcwc)
mod5 <- glm(Height ~ x0+x1+x3+x4+x5, family=gaussian(link="identity"), data=ufcwc)
mod6 <- glm(Height ~ x0+x1+x3+x4+x5+x6, family=gaussian(link="identity"), data=ufcwc)
## Get CV score
mod0_fit <- cv.glm(data=ufcwc, mod0, cost=cost, K=3)$delta[1]
mod1_fit <- cv.glm(data=ufcwc, mod1, cost=cost, K=3)$delta[1]
mod2_fit <- cv.glm(data=ufcwc, mod2, cost=cost, K=3)$delta[1]
mod3_fit <- cv.glm(data=ufcwc, mod3, cost=cost, K=3)$delta[1]
mod4_fit <- cv.glm(data=ufcwc, mod4, cost=cost, K=3)$delta[1]
mod5_fit <- cv.glm(data=ufcwc, mod5, cost=cost, K=3)$delta[1]
mod6_fit <- cv.glm(data=ufcwc, mod6, cost=cost, K=3)$delta[1]
## Compare scores
scores <- c(mod0_fit, mod1_fit, mod2_fit, mod3_fit, mod4_fit, mod5_fit, mod6_fit)
## Order Results
foo = order(Xnew)
x_ord <- X[foo]
y_ord <- Y[foo]
plot(Xnew, Y)
lines(x_ord, fitted(mod6)[foo])
foo = order(Xnew)
x_ord <- Xnew[foo]
y_ord <- Y[foo]
plot(Xnew, Y)
lines(x_ord, fitted(mod6)[foo])
View(dfs)
simulation <- read.csv("scripts/sim_2013_logit.csv")
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
## Read in the logit sims
simulation <- read.csv("scripts/sim_2013_logit.csv")
means
#########################################################################
## Purpose: Using probabilities for each game result, simulate the season
## to compute a distribution of wins ####################################
#########################################################################
## SET WORKING DIRCTORY ##
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
## LIBRARIES
library("dplyr")
library("e1071")
## READ IN OUR FEATURE DATASETS
data <- read.csv("scripts/rpm_dataset.csv")
## ADD home feature and win/loss column
data <- mutate(data, home = 1)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:17]
ytest = test[,18]
xtrain = train[,9:17]
ytrain = train[,18]
## Logistic regression to get probabilities
mylogit <- glm(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home, data=train,
family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_probs <- cbind(test, logit_preds)[, c(2:8, 17:22)]
names(logit_probs)[10] = "home_prob"
##Create the dataset for simulation
num_seasons <- 1000
season_df <- data.frame(matrix(0, nrow=length(unique(logit_probs$home_team)), ncol= num_seasons))
row.names(season_df) <- unique(logit_probs$home_team)
colnames(season_df) = paste("season_", 1:1000, sep="")
## Get the unique match Id's for a given season
match_ids <- unique(logit_probs$match_id)
### Loop through each Season
for(i in 1:1000){
print(paste("season", i))
## Generate the random outcomes
random_outcomes <- runif(length(logit_probs[,1]))
logit_probs <- cbind(logit_probs, random_outcomes)
## Loop through each match ID
for(match in match_ids){
# Using the random number, assign the winner of the game to the data frame
if(logit_probs[logit_probs$match_id == match,]$random_outcomes <= logit_probs[logit_probs$match_id == match,]$home_prob){
## Iterate the season data frame for the Home Team
season_df[as.character(logit_probs[logit_probs$match_id == match,]$home_team), i] = season_df[as.character(logit_probs[logit_probs$match_id == match,]$home_team), i] + 1
}
else{
season_df[as.character(logit_probs[logit_probs$match_id == match,]$visit_team), i] = season_df[as.character(logit_probs[logit_probs$match_id == match,]$visit_team), i] + 1
}
}
## Remove the random outcomes
logit_probs <- logit_probs[,-14]
}
### Check out the results
means <- apply(season_df, 1, mean)
ses <- apply(season_df, 1, sd)
## Save the outcomes
write.csv(season_df, "scripts/sim_2013_logit_df.csv")
write.csv(cbind(means, ses), "scripts/sim_2013_logit.csv")
means
## SET WORKING DIRCTORY ##
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
## Read in the logit sims
simulation <- read.csv("scripts/sim_2013_logit.csv")
simulation <- read.csv("scripts/sim_2013_logit_df.csv")
head(simulation)
simulation <- read.csv("scripts/sim_2013_logit.csv")
head(simulation)
means <- simulation$means
ses <- simulation$ses
season_df <- read.csv("scripts/sim_2013_logit_df.csv")
## Get dataset with the results
results <- read.csv("data/espn_data/team_wins.csv")[,2:4]
results_2013 <- filter(results, year == 2013)[order(results_2013$team),]
## Add in the confidence interval
results_2013 <- cbind(results_2013, means[order(names(means))])
results_2013 <- cbind(results_2013, ses[order(names(ses))])
names(results_2013)[4] = "estimate"
names(results_2013)[5] = "se"
results_2013$lower <- results_2013$estimate - 2*results_2013$se
results_2013$upper <- results_2013$estimate + 2*results_2013$se
results_2013$trapped <- ifelse(results_2013$wins >= results_2013$lower &
results_2013$wins <= results_2013$upper, 1, 0)
results <- read.csv("data/espn_data/team_wins.csv")[,2:4]
results_2013 <- filter(results, year == 2013)[order(results_2013$team),]
results_2013 <- filter(results, year == 2013)
results_2013 <- filter(results, year == 2013)[order(results_2013$team),]
results_2013
## Add in the confidence interval
results_2013 <- cbind(results_2013, means[order(names(means))])
results_2013 <- cbind(results_2013, ses[order(names(ses))])
names(results_2013)[4] = "estimate"
names(results_2013)[5] = "se"
results_2013$lower <- results_2013$estimate - 2*results_2013$se
results_2013$upper <- results_2013$estimate + 2*results_2013$se
results_2013$trapped <- ifelse(results_2013$wins >= results_2013$lower &
results_2013$wins <= results_2013$upper, 1, 0)
typeof(means)
as.vector(means)
means <- as.vector(simulation$means)
ses <- as.vector(simulation$ses)
season_df <- read.csv("scripts/sim_2013_logit_df.csv")
## SET WORKING DIRCTORY ##
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
## Read in the logit sims
simulation <- read.csv("scripts/sim_2013_logit.csv")
means <- as.vector(simulation$means)
ses <- as.vector(simulation$ses)
season_df <- read.csv("scripts/sim_2013_logit_df.csv")
## Get dataset with the results
results <- read.csv("data/espn_data/team_wins.csv")[,2:4]
results_2013 <- filter(results, year == 2013)
results_2013 <- filter(results, year == 2013)[order(results_2013$team),]
## Add in the confidence interval
results_2013 <- cbind(results_2013, means[order(names(means))])
results_2013 <- cbind(results_2013, ses[order(names(ses))])
## SET WORKING DIRCTORY ##
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
## Read in the logit sims
simulation <- read.csv("scripts/sim_2013_logit.csv")
means <- as.vector(simulation$means)
ses <- as.vector(simulation$ses)
season_df <- read.csv("scripts/sim_2013_logit_df.csv")
## Get dataset with the results
results <- read.csv("data/espn_data/team_wins.csv")[,2:4]
results_2013 <- filter(results, year == 2013)
results_2013 <- filter(results, year == 2013)[order(results_2013$team),]
## Add in the confidence interval
results_2013 <- cbind(results_2013, means[order(names(means))])
results_2013 <- cbind(results_2013, ses[order(names(ses))])
names(results_2013)[4] = "estimate"
names(results_2013)[5] = "se"
results_2013
results_2013 <- cbind(results_2013, means[order(names(means))])
order(names(means))
names(means)
names(simulation)
names(simulation$means)
simulation
results_2013 <- cbind(results_2013, means[order(simulation$X)])
results_2013
results_2013 <- cbind(results_2013, ses[order(simulation$X))])
results_2013 <- cbind(results_2013, ses[order(simulation$X)])
names(results_2013)[4] = "estimate"
names(results_2013)[5] = "se"
results_2013$lower <- results_2013$estimate - 2*results_2013$se
results_2013$upper <- results_2013$estimate + 2*results_2013$se
results_2013$trapped <- ifelse(results_2013$wins >= results_2013$lower &
results_2013$wins <= results_2013$upper, 1, 0)
sum(results_2013$trapped)
## Get 2013 Results
results_2013 <- filter(results, year == 2013)
results_2013_sorted <- results_2013[order(results_2013$team),]
## Get the dataset with simulation output for 2013
simulation <- read.csv("scripts/sim_2013_logit.csv")
sim_sort_logit <- simulation[order(simulation$X),]
## Get comparison dataframe and mean and absolute error losses
compare_2013_logit <- cbind(results_2013_sorted, sim_sort_logit)
compare_2013_logit$squared <- (compare_2013_logit$means - compare_2013_logit$wins)^2
rmse <- sqrt(mean(compare_2013_logit$squared))
rmse
compare_2013_logit$absolute <- abs(compare_2013_logit$means - compare_2013_logit$wins)
mae <- mean(compare_2013_logit$absolute)
mae
<<<<<<< HEAD
par(mfrow=c(6, 5))
team_names <- unique(results_2013$team)
for(name in team_names){
season_result <- as.numeric(season_df[name,])
hist(season_result, main=paste("Wins for", toupper(name), sep=" "), xlab="Wins"
, breaks=10)
abline(v=results_2013[results_2013$team == name, "wins"], col="red")
abline(v=results_2013[results_2013$team == name, "lower"], col="blue")
abline(v=results_2013[results_2013$team == name, "upper"], col="blue")
}
## Plot the outcomes
par(mfrow=c(6, 5))
team_names <- unique(results_2013$team)
for(name in team_names){
season_result <- as.numeric(season_df[name,])
hist(season_result, main=paste("Wins for", toupper(name), sep=" "), xlab="Wins"
, breaks=10)
abline(v=results_2013[results_2013$team == name, "wins"], col="red")
abline(v=results_2013[results_2013$team == name, "lower"], col="blue")
abline(v=results_2013[results_2013$team == name, "upper"], col="blue")
}
team_names
team_names <- unique(results_2013$team)
as.numeric(season_df[1,])
names(season_df
)
rownames(season_df)
dim(season_df)
season_df[1,]
season_df[,1]
as.numeric(season_df[season_df$X == "tor",])
## Plot the outcomes
par(mfrow=c(6, 5))
team_names <- unique(results_2013$team)
for(name in team_names){
season_result <- as.numeric(season_df[season_df$X == name,])
hist(season_result, main=paste("Wins for", toupper(name), sep=" "), xlab="Wins"
, breaks=10)
abline(v=results_2013[results_2013$team == name, "wins"], col="red")
abline(v=results_2013[results_2013$team == name, "lower"], col="blue")
abline(v=results_2013[results_2013$team == name, "upper"], col="blue")
}
par(mfrow=c(6, 5))
team_names <- unique(results_2013$team)
for(name in team_names){
season_result <- as.numeric(season_df[season_df$X == name,])
hist(season_result, main=paste("Wins for", toupper(name), sep=" "), xlab="Wins"
, breaks=10)
abline(v=results_2013[results_2013$team == name, "wins"], col="red")
abline(v=results_2013[results_2013$team == name, "lower"], col="blue")
abline(v=results_2013[results_2013$team == name, "upper"], col="blue")
}
=======
## Purpose: Figure out most important covariates for prediction
library(dplyr)
## SET WORKING DIRCTORY ##
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
full_matrix <- read.csv("featuresAll.csv")
dim(full_matrix)
head(full_matrix)
full_matrix <- mutate(full_matrix, home = 1)
?step
names(full_matrix)
full_mod <- glm(homeWin ~ full_matrix[,8:45], family="binomial", data=full_matrix)
full_mod <- glm(homeWin ~., family="binomial", data=full_matrix)
summary(glm)
full_matrix <- as.factor(mutate(full_matrix, home = 1))
full_matrix$home <- factor(full_matrix$home)
head(full_matrix)
summary(glm(homeWin ~ 1, data=full_matrix, family="binomial"))
null_mod <- glm(formula = homeWin ~ 1, family = "binomial", data = full_matrix)
summary(null_mod)
names(full_matrix)
null_mod <- glm(formula = homeWin ~ 1, family = "binomial", data = full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1
,family="binomial", data=full_matrix)
summary(full_mod(
summary(full_mod)
summary(full_mod)
names(full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + home + avg_scoreDiff +
avg_homeWin + avg_scoreDiff_home+avg_win_home+avg_scoreDiff_visit+avg_win_visit+home_rpi+away_rpi+avg_GP+avg_GS+avg_MIN+avg_FG_made+avg_FG_attempted+
avg_FGpercent+ avg_ThreeP_made+avg_ThreeP_attempted+avg_ThreePpercent+avg_FT_made+
avg_FT_attempted+avg_FTpercent+ avg_OR+avg_DR+avg_REB+avg_AST+avg_BLK+
avg_STL+avg_PF+avg_TO+avg_PTS,family="binomial", data=full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + home + avg_scoreDiff +
avg_homeWin + avg_scoreDiff_home+avg_win_home+avg_scoreDiff_visit+avg_win_visit+home_rpi+
away_rpi+avg_GP+avg_GS+avg_MIN+avg_FG_made+avg_FG_attempted+
avg_FGpercent+ avg_ThreeP_made+avg_ThreeP_attempted+avg_ThreePpercent+avg_FT_made+
avg_FT_attempted+avg_FTpercent+avg_OR+avg_DR+avg_REB+avg_AST+avg_BLK+
avg_STL+avg_PF+avg_TO+avg_PTS,family="binomial", data=full_matrix)
head(full_matrix
)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + home + avg_scoreDiff +
avg_scoreDiff_home+avg_win_home+avg_scoreDiff_visit+avg_win_visit+home_rpi+
away_rpi+avg_GP+avg_GS+avg_MIN+avg_FG_made+avg_FG_attempted+
avg_FGpercent+ avg_ThreeP_made+avg_ThreeP_attempted+avg_ThreePpercent+avg_FT_made+
avg_FT_attempted+avg_FTpercent+avg_OR+avg_DR+avg_REB+avg_AST+avg_BLK+
avg_STL+avg_PF+avg_TO+avg_PTS,family="binomial", data=full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + home,
family="binomial", data=full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + avg_scoreDiff +
avg_scoreDiff_home + avg_win_home + avg_scoreDiff_visit + avg_win_visit + home_rpi +
away_rpi + avg_GP + avg_GS+avg_MIN + avg_FG_made + avg_FG_attempted +
avg_FGpercent + avg_ThreeP_made + avg_ThreeP_attempted + avg_ThreePpercent + avg_FT_made +
avg_FT_attempted+ avg_FTpercent+ avg_OR+ avg_DR+ avg_REB+ avg_AST + avg_BLK+
avg_STL+ avg_PF +avg_TO+ avg_PTS, family="binomial", data=full_matrix)
step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction=both)
step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
## SET WORKING DIRCTORY ##
setwd("C:/Users/Lee/game_simulation")
## LIBRARIES
library("dplyr")
library("e1071")
library("randomForest")
## READ IN OUR FEATURE DATASETS
data <- read.csv("scripts/rpm_dataset.csv")
data_rpi <- read.csv("scripts/rpi.csv")
## ADD home feature and win/loss column
data <- mutate(data, home = 1)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
<<<<<<< HEAD
train = filter(data, game_year %in% c(2008, 2009, 2011, 2012))
test = filter(data, game_year == 2013)
=======
train = filter(data, game_year %in% c(2008))
test = filter(data, game_year == 2009)
xtest = test[,9:17]
ytest = test[,18]
xtrain = train[,9:17]
ytrain = train[,18]
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1, data=train, family = "binomial")
summary(mylogit)
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1, data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009))
test = filter(data, game_year == 2010)
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
xtest = test[,9:17]
ytest = test[,18]
xtrain = train[,9:17]
ytrain = train[,18]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
<<<<<<< HEAD
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1 + PER_weight.0 + PER_weight.1, data=train, family = "binomial")
=======
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1, data=train, family = "binomial")
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
<<<<<<< HEAD
## Linear Regression
mylinear <- lm(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home, data=train)
linear_preds <- as.data.frame(predict(mylinear, newdata=xtest, type="response"))
linear_preds$class <- ifelse(linear_preds[,1] >= .5, 1, 0)
linear_preds <- cbind(linear_preds, ytest)
linear_preds$result <- abs(linear_preds[,2] - linear_preds[,3])
linear_accurary <- 1 - sum(linear_preds$result)/length(ytest)
linear_accurary
## Random Forest
rf <- randomForest(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home,
data=train, type="classification")
rf_preds <- as.data.frame(predict(rf, xtest))
rf_preds <- cbind(rf_preds, ytest)
rf_preds$class <- ifelse(rf_preds[,1] >= .5, 1, 0)
rf_preds$result <- abs(rf_preds[,2] - rf_preds[,3])
rf_accurary <- 1 - sum(rf_preds$result)/length(ytest)
rf_accurary
importance(rf_preds)
importance(rf)
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1 + RPM_weight.0: RPM_weight.1, data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
head(data)
train <- mutate(train, RPM_dif = RPM_weight.1 - RPM_weight.0)
head(train)
names(train)
data <- mutate(data, RPM_dif = RPM_weight.1 - RPM_weight.0)
setwd("C:/Users/Lee/game_simulation")
## LIBRARIES
library("dplyr")
library("e1071")
library("randomForest")
## READ IN OUR FEATURE DATASETS
data <- read.csv("scripts/rpm_dataset.csv")
data_rpi <- read.csv("scripts/rpi.csv")
## ADD home feature and win/loss column
data <- mutate(data, home = 1)
data <- mutate(data, RPM_dif = RPM_weight.1 - RPM_weight.0)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
head(train)
## SET WORKING DIRCTORY ##
setwd("C:/Users/Lee/game_simulation")
## LIBRARIES
library("dplyr")
library("e1071")
library("randomForest")
## READ IN OUR FEATURE DATASETS
data <- read.csv("scripts/rpm_dataset.csv")
data_rpi <- read.csv("scripts/rpi.csv")
## ADD home feature and win/loss column
data <- mutate(data, home = 1)
data <- mutate(data, RPM_dif = RPM_weight.1 - RPM_weight.0)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
head(xtest)
mylogit <- glm(homeWin ~ RPM_dif, data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
summary(mylogit)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008))
test = filter(data, game_year == 2009)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
=======
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:17]
ytest = test[,18]
xtrain = train[,9:17]
ytrain = train[,18]
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
<<<<<<< HEAD
mylogit <- glm(homeWin ~ RPM_dif, data=train, family = "binomial")
=======
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1, data=train, family = "binomial")
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
<<<<<<< HEAD
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009))
test = filter(data, game_year == 2010)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
=======
## Set up datasets ##
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:17]
ytest = test[,18]
xtrain = train[,9:17]
ytrain = train[,18]
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
<<<<<<< HEAD
mylogit <- glm(homeWin ~ RPM_dif, data=train, family = "binomial")
=======
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1, data=train, family = "binomial")
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
<<<<<<< HEAD
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010))
test = filter(data, game_year == 2011)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
mylogit <- glm(homeWin ~ RPM_dif, data=train, family = "binomial")
=======
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1 + home, data=train, family = "binomial")
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
<<<<<<< HEAD
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
=======
data <- mutate(data, home = 1)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:17]
ytest = test[,18]
xtrain = train[,9:17]
ytrain = train[,18]
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
<<<<<<< HEAD
mylogit <- glm(homeWin ~ RPM_dif, data=train, family = "binomial")
=======
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1, data=train, family = "binomial")
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
<<<<<<< HEAD
=======
## Linear Regression
mylinear <- lm(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home, data=train)
linear_preds <- as.data.frame(predict(mylinear, newdata=xtest, type="response"))
linear_preds$class <- ifelse(linear_preds[,1] >= .5, 1, 0)
linear_preds <- cbind(linear_preds, ytest)
linear_preds$result <- abs(linear_preds[,2] - linear_preds[,3])
linear_accurary <- 1 - sum(linear_preds$result)/length(ytest)
linear_accurary
## Random Forest
rf <- randomForest(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home,
data=train, type="classification")
rf_preds <- as.data.frame(predict(rf, xtest))
rf_preds <- cbind(rf_preds, ytest)
rf_preds$class <- ifelse(rf_preds[,1] >= .5, 1, 0)
rf_preds$result <- abs(rf_preds[,2] - rf_preds[,3])
rf_accurary <- 1 - sum(rf_preds$result)/length(ytest)
rf_accurary
install_packages("randomForest")
install.packages("randomForest")
setwd("C:/Users/Lee/game_simulation")
## LIBRARIES
library("dplyr")
library("e1071")
library("randomForest")
## READ IN OUR FEATURE DATASETS
data <- read.csv("scripts/rpm_dataset.csv")
data_rpi <- read.csv("scripts/rpi.csv")
## ADD home feature and win/loss column
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
data <- mutate(data, home = 1)
data <- mutate(data, RPM_dif = RPM_weight.1 - RPM_weight.0)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
<<<<<<< HEAD
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2013))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
=======
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:17]
ytest = test[,18]
xtrain = train[,9:17]
ytrain = train[,18]
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
<<<<<<< HEAD
mylogit <- glm(homeWin ~ RPM_dif, data=train, family = "binomial")
=======
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1, data=train, family = "binomial")
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
## Linear Regression
mylinear <- lm(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home, data=train)
linear_preds <- as.data.frame(predict(mylinear, newdata=xtest, type="response"))
linear_preds$class <- ifelse(linear_preds[,1] >= .5, 1, 0)
linear_preds <- cbind(linear_preds, ytest)
linear_preds$result <- abs(linear_preds[,2] - linear_preds[,3])
linear_accurary <- 1 - sum(linear_preds$result)/length(ytest)
linear_accurary
## Random Forest
rf <- randomForest(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home,
data=train, type="classification")
rf_preds <- as.data.frame(predict(rf, xtest))
rf_preds <- cbind(rf_preds, ytest)
rf_preds$class <- ifelse(rf_preds[,1] >= .5, 1, 0)
rf_preds$result <- abs(rf_preds[,2] - rf_preds[,3])
rf_accurary <- 1 - sum(rf_preds$result)/length(ytest)
rf_accurary
<<<<<<< HEAD
nba_one <- "http://www.nba.com/games/20101201/CHANOH/gameinfo.html"
sample_game <- readLines(nba_one)
head(sample_game)
sample_game
head(sample_game)
sample_game
first_date <- "http://www.nba.com/gameline/20091001/"
head(data)
doc <- htmlPare(sample_game)
library(XML)
doc <- htmlParse(sample_game)
doc
=======
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1 + PER_weight.0 + PER_weight.1, data=train, family = "binomial")
summary(mylogit
)
mylogit <- glm(homeWin ~ RPM_weight.0 + RPM_weight.1 + PER_weight.0 + PER_weight.1, data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
train = filter(full_matrix, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(full_matrix, game_year == 2012)
head(train)
library(lars)
install.packages("lars")
library(lars)
## SET WORKING DIRCTORY ##
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
# Read in the full feature matrix
full_matrix <- read.csv("featuresAll.csv")
full_matrix <- read.csv("featuresAll.csv")
head(full_matrix)
names(full_matrix)
train = filter(full_matrix, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(full_matrix, game_year == 2012)
xtest = test[,8:44]
ytest = test[,2]
xtrain = train[,8:44]
ytrain = train[,2]
head(train)
dim(train)
dim(test)
?lars
lars(xtrain, ytrain, type="lasso")
lars(xtrain, ytrain)
xtest = as.matrix(test[,8:44])
ytest = as.matrix(test[,2])
xtrain = as.matrix(train[,8:44])
ytrain = as.matrix(train[,2])
# Fit a LARS object
lars(xtrain, ytrain)
source('~/.active-rstudio-document', echo=TRUE)
lasso_mod <- lars(xtrain, ytrain, type="lasso")
names(lasso_mod)
lasso_mod$beta
summary(lasso_mod)
fits <- predict.lars(lasso_mod, xtest, type="fit")
head(fits)
dim(fits
)
str(fits)
coef4.1 <- coef(lasso_mod, s=4.1, mode="norm")
coef4.1
coef4.1 <- predict(lasso_mod, s=4.1, type="coef", mode="norm")
coef4.1
fits <- predict.lars(lasso_mod, xtest, type="fit")
head(fits)
lasso_mod
names(lasso_mod)
lasso_mod$coef
lasso_mod$lambda
lasso_mod$type
lasso_mod$call
lasso_mod$entry
lasso_mod$beta
lasso_mod$mu
fits <- predict.lars(lasso_mod, xtest, type="fit")
fits <- predict.lars(lasso_mod, xtest, type="fit")
fits[1]
fits[2]
fits[3]
fits[4]
dim(fits[4])
length(fits[4])
head(fits)
str(fits)
fits[,56]
fits[4,56]
fits[4]
fits[4,55]
p <- fits[4]
p <- as.data.frame(fits[4])
head(p)
p[,56]
length(p[,56])
lasso_probs <- p[,56]
lasso_probs$class <- ifelse(lasso_probs[,2] > lasso_probs[,1], 1, 0)
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs <- as.data.frame(p[,56])
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs
lasso_probs <- cbind(lasso_probs, ytest)
lasso_probs
lasso_probs$result <- abs(lasso_probs[,2] - lasso_probs[,3])
accuracy <- 1 - sum(lasso_probs$result)/length(ytest)
accuracy
train = filter(full_matrix, game_year %in% c(2008, 2009, 2010, 2011, 2012))
test = filter(full_matrix, game_year == 2013)
xtest = as.matrix(test[,8:44])
ytest = as.matrix(test[,2])
xtrain = as.matrix(train[,8:44])
ytrain = as.matrix(train[,2])
# Fit a LARS object
lasso_mod <- lars(xtrain, ytrain, type="lasso")
fits <- predict.lars(lasso_mod, xtest, type="fit")
p <- as.data.frame(fits[4])
lasso_probs <- as.data.frame(p[,56])
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs <- cbind(lasso_probs, ytest)
lasso_probs$result <- abs(lasso_probs[,2] - lasso_probs[,3])
accuracy <- 1 - sum(lasso_probs$result)/length(ytest)
accuracy
train = filter(full_matrix, game_year %in% c(2008))
test = filter(full_matrix, game_year == 2009)
xtest = as.matrix(test[,8:44])
ytest = as.matrix(test[,2])
xtrain = as.matrix(train[,8:44])
ytrain = as.matrix(train[,2])
# Fit a LARS object
lasso_mod <- lars(xtrain, ytrain, type="lasso")
fits <- predict.lars(lasso_mod, xtest, type="fit")
p <- as.data.frame(fits[4])
lasso_probs <- as.data.frame(p[,56])
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs <- cbind(lasso_probs, ytest)
lasso_probs$result <- abs(lasso_probs[,2] - lasso_probs[,3])
accuracy <- 1 - sum(lasso_probs$result)/length(ytest)
accuracy
train = filter(full_matrix, game_year %in% c(2008, 2009))
test = filter(full_matrix, game_year == 2010)
xtest = as.matrix(test[,8:44])
ytest = as.matrix(test[,2])
xtrain = as.matrix(train[,8:44])
ytrain = as.matrix(train[,2])
# Fit a LARS object
lasso_mod <- lars(xtrain, ytrain, type="lasso")
fits <- predict.lars(lasso_mod, xtest, type="fit")
p <- as.data.frame(fits[4])
lasso_probs <- as.data.frame(p[,56])
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs <- cbind(lasso_probs, ytest)
lasso_probs$result <- abs(lasso_probs[,2] - lasso_probs[,3])
accuracy <- 1 - sum(lasso_probs$result)/length(ytest)
accuracy
train = filter(full_matrix, game_year %in% c(2008, 2009, 2010))
test = filter(full_matrix, game_year == 2011)
xtest = as.matrix(test[,8:44])
ytest = as.matrix(test[,2])
xtrain = as.matrix(train[,8:44])
ytrain = as.matrix(train[,2])
# Fit a LARS object
lasso_mod <- lars(xtrain, ytrain, type="lasso")
fits <- predict.lars(lasso_mod, xtest, type="fit")
p <- as.data.frame(fits[4])
lasso_probs <- as.data.frame(p[,56])
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs <- cbind(lasso_probs, ytest)
lasso_probs$result <- abs(lasso_probs[,2] - lasso_probs[,3])
accuracy <- 1 - sum(lasso_probs$result)/length(ytest)
accuracy
train = filter(full_matrix, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(full_matrix, game_year == 2012)
xtest = as.matrix(test[,8:44])
ytest = as.matrix(test[,2])
xtrain = as.matrix(train[,8:44])
ytrain = as.matrix(train[,2])
# Fit a LARS object
lasso_mod <- lars(xtrain, ytrain, type="lasso")
fits <- predict.lars(lasso_mod, xtest, type="fit")
p <- as.data.frame(fits[4])
lasso_probs <- as.data.frame(p[,56])
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs <- cbind(lasso_probs, ytest)
lasso_probs$result <- abs(lasso_probs[,2] - lasso_probs[,3])
accuracy <- 1 - sum(lasso_probs$result)/length(ytest)
accuracy
## Lasso
train = filter(full_matrix, game_year %in% c(2008, 2009, 2010, 2011, 2012))
test = filter(full_matrix, game_year == 2013)
xtest = as.matrix(test[,8:44])
ytest = as.matrix(test[,2])
xtrain = as.matrix(train[,8:44])
ytrain = as.matrix(train[,2])
# Fit a LARS object
lasso_mod <- lars(xtrain, ytrain, type="lasso")
fits <- predict.lars(lasso_mod, xtest, type="fit")
p <- as.data.frame(fits[4])
lasso_probs <- as.data.frame(p[,56])
lasso_probs$class <- ifelse(lasso_probs[,1] >= .5, 1, 0)
lasso_probs <- cbind(lasso_probs, ytest)
lasso_probs$result <- abs(lasso_probs[,2] - lasso_probs[,3])
accuracy <- 1 - sum(lasso_probs$result)/length(ytest)
accuracy
>>>>>>> 9da187c2fd605aa9904fe34ea8e4aab9073fa807
>>>>>>> 7f763f76725fb85f2dbe3f0e30b27aae3d6208b0
