newx <- seq(min(island$area), max(island$area), length=18)
preds <- predict(point_estimates, newdata = data.frame(x=newx), interval = 'confidence')
preds
newx
preds <- predict(point_estimates, newdata = newx, interval = 'confidence')
preds <- predict(point_estimates, newdata = ;ist(newx), interval = 'confidence')
preds <- predict(point_estimates, newdata = list(newx), interval = 'confidence')
preds
plot(point_estimates, data = island)
plot(a, y)
points(a, fitted(point_estimates), type="l")
polygon(c(rev(newx), newx), c(rev(preds[ ,3]), preds[ ,2]), col = 'grey80', border = NA)
newx <- seq(min(island$area), max(island$area), length=100)
preds <- predict(point_estimates, newdata = list(newx), interval = 'confidence')
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
island
newx <- seq(min(a), max(a), length=100)
newx
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
preds
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
plot(a, y)
points(a~y, fitted(point_estimates), type="l")
polygon(c(rev(newx), newx), c(rev(preds[ ,3]), preds[ ,2]), col = 'grey80', border = NA)
points(a~y, fitted(point_estimates), type="n")
points(a~y, type="n")
plot(y~a)
polygon(c(rev(newx), newx), c(rev(preds[ ,3]), preds[ ,2]), col = 'grey80', border = NA)
newx <- seq(min(a), max(a), length=100)
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
head(news)
head(newx)
head(predict(point_estimates))
summary(point_estimates)
point_estimates <- lm(y ~ poly(log(a), 2))
newx <- seq(min(a), max(a), length=100)
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
# plot
plot(y~a)
points(a~y, type="n")
polygon(c(rev(newx), newx), c(rev(preds[ ,3]), preds[ ,2]), col = 'grey80', border = NA)
newx <- seq(min(a), max(a), length=18)
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
# plot
plot(y~a)
points(a~y, type="n")
# add fill
polygon(c(rev(newx), newx), c(rev(preds[ ,3]), preds[ ,2]), col = 'grey80', border = NA)
newx <- seq(min(a), max(a), length=18)
newx
point_estimates <- lm(y ~ poly(log(a), 2))
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
attach(island)
a = area
a
point_estimates <- lm(y ~ poly(log(a), 2))
newx <- seq(min(a), max(a), length=18)
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
newx <- seq(min(a), max(a), length=100)
preds <- predict(point_estimates, newdata = data.frame(newx), interval = 'confidence')
# plot
830-728
d = qf(.95,2,16)
n=18
stuff = sqrt(2*d)*sqrt( (1/n) + ((x-xbar)ˆ2/ssx))*sigma.hat
upper = r.hat + stuff
lower = r.hat - stuff
lines(x,upper,lty=2,col=2,lwd=3); lines(x,lower,lty=2,col=2,lwd=3)
#PROBLEM 7!
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
attach(island)
a = area
logarea = log(a)
poly_area = poly(logarea, 2)
z = extinctions
n = atrisk
y = z/n
plot(log(a), y)
point_estimates <- lm(y ~ poly(log(a), 2))
plot(a, y)
points(a, fitted(point_estimates), type="l")
#Confidence Bands
d = qf(.95,2,16)
n=18
stuff = sqrt(2*d)*sqrt( (1/n) + ((x-xbar)ˆ2/ssx))*sigma.hat
upper = r.hat + stuff
lower = r.hat - stuff
lines(x,upper,lty=2,col=2,lwd=3); lines(x,lower,lty=2,col=2,lwd=3)
#Mini Project
library(alr3, quietly=TRUE)
data(water)
attach(water)
#2D EDA
pairs(~BSAAM+APMAM+APSAB+APSLAKE+OPBPC+OPRC+OPSLAKE,data=water)
#Test_lms
mod1 <- lm(BSAAM~APSLAKE+APMAM)
mod2 <- lm(BSAAM~APSLAKE+OPSLAKE)
mod3 <- lm(BSAAM~APSAB+APSLAKE+OPRC+OPSLAKE)
mod4 <- lm(BSAAM~APSAB+APSLAKE)
mod5 <- lm(BSAAM~OPRC+OPSLAKE)
decision_mod <- lm(BSAAM~APSLAKE+OPRC)
summary(mod4)
summary(mod5)
plot(BSAAM)
abline(mod1)
abline(mod2)
abline(mod3)
#Looking at the smallest possible stream runoff
pred_vals <- data.frame(APSLAKE=min(water[,4]), OPRC=min(water[,6]))
pred_vals_ly <- data.frame(APSLAKE=water[30,4], OPRC=water[30,6])
predict(decision_mod, pred_vals, interval="predict")
predict(decision_mod, pred_vals_ly, interval="predict")
#Problem Two
library(MASS)
n = 100
x = (1:100)/n
y = 2 + 3*x + rnorm(n,0,.1)
y[90] = 2
out1 <- lm(y~x)
out2 <- rlm(y ~ x)
#Problem Four
library(MASS)
attach(wtloss)
hist(Weight)
hist(dif(Weight)
)
hist(diff(Weight)
)
?diff
acf(Weight)
#Variance as a function of X
var_lm <- lm((info$residuals)^2 ~ Days)
summary(var_lm)
#Weighted least S
weight_fitted <- (fitted(var_lm))^2
out2 <- out <- nls(Weight ~ b0 + b1 * 2^(-Days/b2), data=wtloss, start=list(b0=90, b1=95, b2=120),
weights=(1/weight_fitted^2))
info2 <- summary(out2)
b2 = info2$parameters[,1]
compare_params <- rbind(b, b2)
row.names(compare_params) = c("unweighted", "weighted")
compare_params
b
names(b)
names(info)
info$sigma
info
info$parameters[,2]
?col.names
?colnames
plot(a,y, xlab = "Body Weight (kg)", ylab = "Heart Weight (g)", ...)
plot(a,y)
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
attach(island)
a = area
logarea = log(a)
poly_area = poly(logarea, 2)
z = extinctions
n = atrisk
y = z/n
plot(log(a), y)
point_estimates <- lm(y ~ poly(log(a), 2))
plot(a, y)
points(a, fitted(point_estimates), type="l")
x = seq(min(a),max(a),length=1000)
x
newx <- seq(min(area), max(area), length.out=100)
preds <- predict(point_estimates, newdata = data.frame(x=newx),
interval = 'confidence')
newx <- seq(min(area), max(area), length.out=100)
preds <- predict(point_estimates, newdata = data.frame(newx),
interval = 'confidence')
newx <- seq(min(island$area), max(island$area), length=100)
preds <- predict(point_estimates, newdata = data.frame(x=newx),
interval = 'confidence')
preds
newx <- seq(min(island$area), max(island$area), length=100)
news
new2
newx
newx <- seq(min(island$area), max(island$area), length=18)
preds <- predict(point_estimates, newdata = data.frame(x=newx),
interval = 'confidence')
preds
point_estimates <- lm(y ~ a + poly(log(a), 2))
plot(a, y)
points(a, fitted(point_estimates), type="l")
newx <- seq(min(island$area), max(island$area), length=18)
preds <- predict(point_estimates, newdata = data.frame(x=newx),
interval = 'confidence')
newx <- seq(min(island$area), max(island$area), length=100)
preds <- predict(point_estimates, newdata = data.frame(x=newx),
interval = 'confidence')
preds
plot(point_estimates)
preds <- predict(point_estimates, newdata = lisx=newx), interval = 'confidence')
preds <- predict(point_estimates, newdata = list(newx), interval = 'confidence')
newx <- seq(min(island$area), max(island$area), length=100)
preds <- predict(point_estimates, newdata = list(newx), interval = 'confidence')
preds
point_estimates <- lm(y ~ a + poly(log(a), 2))
plot(a, y)
points(a, fitted(point_estimates), type="l")
newx <- seq(min(island$area), max(island$area), length=100)
preds <- predict(point_estimates, newdata = list(newx), interval = 'confidence')
preds
newx <- seq(min(island$area), max(island$area), length=100)
newsx
newx
fitted(point_estimates)
fitted(point_estimates[,"Lwr"])
x <- seq(min(a), max(a), length.out = 20)
a
x <- seq(max(a), min(a), length.out = 20)
lines(x, fitted[, "lwr"], lty = "dotted")
x
x <- seq(min(a), max(a), length.out = 20)
x
fitted <- predict(point, interval = "confidence")
fitted <- predict(point_estimates, interval = "confidence")
lines(x, fitted[, "fit"])
fitted <- predict(point_estimates, interval = "confidence")
plot(a,y)
lines(x, fitted[, "fit"])
x <- seq(min(a), max(a), length.out = 100)
plot(a,y)
x <- seq(min(a), max(a), length.out = 100)
fitted <- predict(point_estimates, interval = "confidence")
lines(x, fitted[, "fit"])
x <- seq(min(a), max(a), length.out = 18)
fitted <- predict(point_estimates, interval = "confidence")
lines(x, fitted[, "fit"])
# now the confidence bands
lines(x, fitted[, "lwr"], lty = "dotted")
lines(x, fitted[, "upr"], lty = "dotted")
x <- seq(max(a), min(a), length.out = 18)
fitted <- predict(point_estimates, interval = "confidence")
lines(x, fitted[, "fit"])
# now the confidence bands
lines(x, fitted[, "lwr"], lty = "dotted")
lines(x, fitted[, "upr"], lty = "dotted")
plot(a,y)
points(a, fitted(point_estimates), type="l")
plot(a,y)
fitted <- predict(point_estimates, interval = "confidence")
lines(x, fitted[, "fit"])
point_estimates <- lm(y ~ poly(log(a), 2))
plot(a,y)
points(a, fitted(point_estimates), type="l")
x <- seq(max(a), min(a), length.out = 18)
fitted <- predict(point_estimates, interval = "confidence")
lines(x, fitted[, "fit"])
# now the confidence bands
lines(x, fitted[, "lwr"], lty = "dotted")
lines(x, fitted[, "upr"], lty = "dotted")
plot(a,y)
points(a, fitted(point_estimates), type="l")
x <- seq(max(a), min(a), length.out = 100)
fitted <- predict(point_estimates, interval = "confidence")
lines(x, fitted[, "fit"])
# now the confidence bands
lines(x, fitted[, "lwr"], lty = "dotted")
lines(x, fitted[, "upr"], lty = "dotted")
point_estimates <- lm(y ~ poly_area)
x <- seq(0, 1, length.out = 20)
x <- seq(0, 1, length.out = 100)
x <- seq(min(a), max(a), length.out = 100)
point_estimates <- lm(y ~ poly_area)
fitted <- predict(model, interval = "confidence")
fitted <- predict(point_estimates, interval = "confidence")
plot(a, y)
lines(x, fitted[, "fit"])
x <- seq(min(a), max(a), length.out = 18)
# fit a quadratic
fitted <- predict(point_estimates, interval = "confidence")
# plot the data and the fitted line
plot(a, y)
lines(x, fitted[, "fit"])
# now the confidence bands
lines(x, fitted[, "lwr"], lty = "dotted")
lines(x, fitted[, "upr"], lty = "dotted")
point_estimates <- lm(y ~ poly_area)
fitted <- predict(point_estimates, interval = "confidence")
plot(log(a), y)
point_estimates <- lm(y ~ poly_area)
mod_a <- lm(y ~poly_area)
x <- seq(min(a), max(a), length.out = 18)
plot(a, y)
points(a, fitted(point_estimates), type="l")
point_estimates
fitted <- predict(point_estimates, interval = "confidence")
fitted
out <- lm(y ~ log(x))
fitted <- predict(out, interval = "confidence")
fitted
plot(log(a), y)
lines(x, fitted[, "fit"])
# now the confidence bands
lines(x, fitted[, "lwr"], lty = "dotted")
lines(x, fitted[, "upr"], lty = "dotted")
out <- lm(y ~ log(x))
out <- lm(y ~ log(a))
fitted <- predict(out, interval = "confidence")
fitted
out <- lm(y ~ log(a))
y = Z/n
z = extinctions
n = atrisk
y = Z/n
y = z/n
y
attach(island)
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
island
attach(island)
head(island)
x = area
y = extinctions/atrisk
y
out <- lm(y ~ log(x))
fitted <- predict(out, interval = "confidence")
fitted
fitted <- predict(out, interval = "confidence")
lines(log(x), fitted[,"fit"])
lines(log(x), fitted[,"lwr"])
lines(log(x), fitted[,"upr"])
out <- lm(y ~ poly(log(x), 2))
fitted <- predict(out, interval = "confidence")
plot(log(x), y)
out <- lm(y ~ poly(log(x), 2))
fitted <- predict(out, interval = "confidence")
lines(log(x), fitted[,"fit"])
lines(log(x), fitted[,"upr"])
lines(log(x), fitted[,"lwr"])
plot(log(x), y, main= "Confidence bands for Log Squared Fit", xlab="Log Area")
out <- lm(y ~ poly(log(x), 2))
fitted <- predict(out, interval = "confidence")
lines(log(x), fitted[,"fit"])
lines(log(x), fitted[,"upr"])
lines(log(x), fitted[,"lwr"])
# fit a quadratic
# plot the data and the fitted line
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
attach(island)
x = area
y = extinctions/atrisk
plot(log(x), y, main= "Confidence bands for Log Squared Fit", xlab="Log Area")
out <- lm(y ~ poly(log(x), 2))
fitted <- predict(out, interval = "confidence")
lines(log(x), fitted[,"fit"])
lines(log(x), fitted[,"upr"])
lines(log(x), fitted[,"lwr"])
plot(out$residuals, fitted)
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
attach(island)
x = area
y = extinctions/atrisk
plot(log(x), y, main= "Confidence bands for Log Squared Fit", xlab="Log Area")
out <- lm(y ~ poly(log(x), 2))
fitted <- predict(out, interval = "confidence")
lines(log(x), fitted[,"fit"])
lines(log(x), fitted[,"upr"])
lines(log(x), fitted[,"lwr"])
plot(out$residuals, fitted)
plot(out$residuals)
abline(0,0)
qqnorm(out$residuals, main="QQPlot"); abline(0,1)
qqnorm(rstandard(out$residuals), main="QQPlot"); abline(0,1)
qqnorm(rstandard(out$residuals), main="QQPlot"); abline(0,1)
plot(wat_lm,c(2,4,5))
qqnorm(rstandard(out$residuals), main="QQPlot"); abline(0,1)
qqnorm(rstandard(out), main="QQPlot"); abline(0,1)
par(mfrow=c(2,2))
plot(out$residuals)
abline(0,0)
qqnorm(rstandard(out), main="QQPlot"); abline(0,1)
plot(out$residuals, fitted)
plot(out$residuals, fitted(out))
abline(0,0)
qqnorm(rstandard(out), main="QQPlot"); abline(0,1)
plot(out)
plot(out)
box_score <- as.data.frame(matrix(0, nrow=9, ncol=10))
box_score
log()
getwd()
setwd("C:/Users//Lee/game_simulation//data")
ls
read.csv("all_data.csv")
ad <- read.csv("all_data.csv")
head(as)
head(ad)
id <- read.csv("all_data.csv")
id <- read.csv("input_data.csv.csv")
id <- read.csv("input_data.csv")
id
head(id)
#Load the XML Library
library(XML)
###### URLs
url<-paste0("http://www.basketball-reference.com/players/",letters,"/")
#Set the years from which data is available
years <- 1950:2014
#Set the urls for the data we want
totals_url <- paste0("http://www.basketball-reference.com/leagues/NBA_", years, "_totals.html")
advanced_url <- paste0("http://www.basketball-reference.com/leagues/NBA_", years, "_advanced.html")
#Set the length of the tables that we are scraping from
totals_len<-length(totals_url)
advanced_len<-length(advanced_url)
#Initialize both the totals and advanced tables
totals_table <- readHTMLTable(totals_url[1])[[1]]
totals_table$year <- 1950
advanced_table <- readHTMLTable(advanced_url[1])[[1]]
advanced_table$year <- 1950
#Append together all of the totals data
for (i in 2:totals_len) {
#Create a temporary table, and then append on a variable that contains the year
temp_table <- readHTMLTable(totals_url[i])[[1]]
temp_table$year <- i + 1949
totals_table<-rbind(totals_table,temp_table)
}
#Append together all of the advanced data
for (i in 2:advanced_len) {
#Create a temporary table, and then append on a variable that contains the year
temp_table <- readHTMLTable(advanced_url[i])[[1]]
temp_table$year <- i + 1949
advanced_table<-rbind(advanced_table,temp_table)
}
#Combine the output of these two tables, and get rid of the default rows which don't
all_table <- as.data.frame(subset(cbind(totals_table, advanced_table), Player != "Player"))
all_table_revised <- all_table[,!grepl(".1", names(all_table))]
#Write the polished data frame to a CSV
write.csv(all_table_revised, file = "data/bball_ref_data.csv")
install.packages("XML")
#Load the XML Library
library(XML)
###### URLs
url<-paste0("http://www.basketball-reference.com/players/",letters,"/")
#Set the years from which data is available
years <- 1950:2014
#Set the urls for the data we want
totals_url <- paste0("http://www.basketball-reference.com/leagues/NBA_", years, "_totals.html")
advanced_url <- paste0("http://www.basketball-reference.com/leagues/NBA_", years, "_advanced.html")
#Set the length of the tables that we are scraping from
totals_len<-length(totals_url)
advanced_len<-length(advanced_url)
#Initialize both the totals and advanced tables
totals_table <- readHTMLTable(totals_url[1])[[1]]
totals_table$year <- 1950
advanced_table <- readHTMLTable(advanced_url[1])[[1]]
advanced_table$year <- 1950
#Append together all of the totals data
for (i in 2:totals_len) {
#Create a temporary table, and then append on a variable that contains the year
temp_table <- readHTMLTable(totals_url[i])[[1]]
temp_table$year <- i + 1949
totals_table<-rbind(totals_table,temp_table)
}
#Append together all of the advanced data
for (i in 2:advanced_len) {
#Create a temporary table, and then append on a variable that contains the year
temp_table <- readHTMLTable(advanced_url[i])[[1]]
temp_table$year <- i + 1949
advanced_table<-rbind(advanced_table,temp_table)
}
#Combine the output of these two tables, and get rid of the default rows which don't
all_table <- as.data.frame(subset(cbind(totals_table, advanced_table), Player != "Player"))
all_table_revised <- all_table[,!grepl(".1", names(all_table))]
#Write the polished data frame to a CSV
write.csv(all_table_revised, file = "data/bball_ref_data.csv")
head(all_table_revised)
getwd()
setwd("C:/Users/Lee/game_simulation")
write.csv(all_table_revised, file = "data/bball_ref_data.csv")
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
head(island)
a = area
a = island$area
ar = island$atrisk
e = island$extinctions
y = z/n
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
attach(island)
x = island$area
n = island$atrisk
z = island$extinctions
y = z/n
y
island <- read.table("http://www.stat.cmu.edu/~roeder/stat707/=data/=data/sleuth/case2101.asc", header=TRUE)
attach(island)
x = island$area
n = island$atrisk
z = island$extinctions
y = z/n
var(y)
getwd()
read.csv(""data/espn_data/gameDetail.csv"")
read.csv("data/espn_data/gameDetail.csv")
head(read.csv("data/espn_data/gameDetail.csv"))
head(read.csv("data/espn_data/gameScore.csv"))
games <- read.csv("data/espn_data/gameScore.csv")
head(games)
hist(fate)
hist(games$date)
tail(games)
games$date
dim(games)
data_input <- read.csv("data//merged_input_data.csv")
head(data_input)
head(games)
gd = head(read.csv("data/espn_data/gameDetail.csv"))
head(gd)
