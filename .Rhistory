results_2012_sorted <- results_2012[order(results_2012$team),]
## Get the dataset with simulation output for 2012
simulation <- read.csv("scripts/sim_2012.csv")
sim_sort <- simulation[order(simulation$X),]
## Get comparison dataframe and mean and absolute error losses
compare_2012 <- cbind(results_2012_sorted, sim_sort)
compare_2012$squared <- (compare_2012$means - compare_2012$wins)^2
rmse <- sqrt(mean(compare_2012$squared))
rmse
compare_2012$absolute <- abs(compare_2012$means - compare_2012$wins)
mae <- mean(compare_2012$absolute)
mae
## SET WORKING DIRCTORY ##
setwd("C:/Users/Lee/game_simulation")
## LIBRARIES
library("dplyr")
library("e1071")
library("randomForest")
## READ IN OUR FEATURE DATASETS
data <- read.csv("scripts/rpm_dataset.csv")
data_rpi <- read.csv("scripts/rpi.csv")
## ADD home feature and win/loss column
data <- mutate(data, home = 1)
data <- mutate(data, RPM_dif = RPM_weight.1 - RPM_weight.0)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2013))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
rf <- randomForest(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home,
data=train, type="classification")
importance(rf)
xtable(importance(rf))
library(xtable)
xtable(importance(rf))
## Purpose: Figure out most important covariates for prediction
library(dplyr)
library(lars)
## SET WORKING DIRCTORY ##
setwd("C:/Users/leeri_000/basketball_stats/game_simulation")
# Read in the full feature matrix
full_matrix <- read.csv("featuresAll.csv")
## Set up full and null models
null_mod <- glm(formula = homeWin ~ 1, family = "binomial", data = full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + avg_scoreDiff +
avg_scoreDiff_home + avg_win_home + avg_scoreDiff_visit + avg_win_visit + home_rpi +
away_rpi + avg_GP + avg_GS+avg_MIN + avg_FG_made + avg_FG_attempted +
avg_FGpercent + avg_ThreeP_made + avg_ThreeP_attempted + avg_ThreePpercent + avg_FT_made +
avg_FT_attempted+ avg_FTpercent+ avg_OR+ avg_DR+ avg_REB+ avg_AST + avg_BLK+
avg_STL+ avg_PF +avg_TO+ avg_PTS, family="binomial", data=full_matrix)
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
dim(full_matrix)
head(full_matrix)
plot(full_matrix$home_rpi)
plot(full_matrix$home_rpi)
plot(full_matrix$home_rpi)
plot(full_matrix$home_rpi)
plot(full_matrix$home_rpi)
plot(full_matrix$home_rpi)
plot(full_matrix$home_rpi)
full_matrix <- read.csv("featuresAll.csv")
## Set up full and null models
null_mod <- glm(formula = homeWin ~ 1, family = "binomial", data = full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + avg_scoreDiff +
avg_scoreDiff_home + avg_win_home + avg_scoreDiff_visit + avg_win_visit + log(home_rpi) +
log(away_rpi) + avg_GP + avg_GS+avg_MIN + avg_FG_made + avg_FG_attempted +
avg_FGpercent + avg_ThreeP_made + avg_ThreeP_attempted + avg_ThreePpercent + avg_FT_made +
avg_FT_attempted+ avg_FTpercent+ avg_OR+ avg_DR+ avg_REB+ avg_AST + avg_BLK+
avg_STL+ avg_PF +avg_TO+ avg_PTS, family="binomial", data=full_matrix)
## Stepwise model selection
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
?step
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both", k=log(n))
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both",
k = log(n))
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
importance(rf)
means
results_2013
library(dplyr)
## SET WORKING DIRCTORY ##
setwd("C:/Users/Lee/game_simulation")
## Read in the logit sims
simulation <- read.csv("scripts/sim_2013_logit.csv")
means <- as.vector(simulation$means)
ses <- as.vector(simulation$ses)
season_df <- read.csv("scripts/sim_2013_logit_df.csv")
## Get dataset with the results
results <- read.csv("data/espn_data/team_wins.csv")[,2:4]
results_2013 <- filter(results, year == 2013)
results_2013 <- filter(results, year == 2013)[order(results_2013$team),]
## Add in the confidence interval
results_2013 <- cbind(results_2013, means[order(simulation$X)])
results_2013 <- cbind(results_2013, ses[order(simulation$X)])
names(results_2013)[4] = "estimate"
names(results_2013)[5] = "se"
results_2013$lower <- results_2013$estimate - 2*results_2013$se
results_2013$upper <- results_2013$estimate + 2*results_2013$se
results_2013$trapped <- ifelse(results_2013$wins >= results_2013$lower &
results_2013$wins <= results_2013$upper, 1, 0)
results_2013
rf <- randomForest(homeWin ~ RPM_dif, data=train, type="classification")
train = filter(data, game_year %in% c(2008, 2009, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
mylogit <- glm(homeWin ~ RPM_dif, data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
mylinear <- lm(homeWin ~ RPM_weight.0 + ORPM_weight.0 + DRPM_weight.0 + PER_weight.0 +
RPM_weight.1 + ORPM_weight.1 + DRPM_weight.1 + PER_weight.1 + home, data=train)
linear_preds <- as.data.frame(predict(mylinear, newdata=xtest, type="response"))
linear_preds$class <- ifelse(linear_preds[,1] >= .5, 1, 0)
linear_preds <- cbind(linear_preds, ytest)
linear_preds$result <- abs(linear_preds[,2] - linear_preds[,3])
linear_accurary <- 1 - sum(linear_preds$result)/length(ytest)
linear_accurary
## Random Forest
rf <- randomForest(homeWin ~ RPM_dif, data=train, type="classification")
rf_preds <- as.data.frame(predict(rf, xtest))
rf_preds <- cbind(rf_preds, ytest)
rf_preds$class <- ifelse(rf_preds[,1] >= .5, 1, 0)
rf_preds$result <- abs(rf_preds[,2] - rf_preds[,3])
rf_accurary <- 1 - sum(rf_preds$result)/length(ytest)
rf_accurary
plot(RPM_weight.0, ORPM_weight.0)
plot(train$RPM_weight.0, train$ORPM_weight.0)
plot(train$RPM_weight.0, train$ORPM_weight.0)
plot(train$RPM_weight.0, train$ORPM_weight.0)
plot(train$RPM_weight.0, train$ORPM_weight.0)
plot(train$RPM_weight.0, train$ORPM_weight.0)
plot(train$RPM_weight.0, train$ORPM_weight.0)
plot(train$RPM_weight.0, train$ORPM_weight.0)
data <- mutate(data, home = 1)
data <- mutate(data, RPM_dif = RPM_weight.1 - RPM_weight.0)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2011, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010))
test = filter(data, game_year == 2011)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008))
test = filter(data, game_year == 2009)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Set up datasets ##
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009))
test = filter(data, game_year == 2010)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010))
test = filter(data, game_year == 2011)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
mylogit <- glm(homeWin ~ RPM_weight.0 + ORPM_weight.0 , data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain, ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
## Logistic Regression
mylogit <- glm(homeWin ~ RPM_weight.0 + ORPM_weight.0 , data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
mylogit <- glm(homeWin ~ RPM_weight.0 + ORPM_weight.0 + PER_weight.1 + PER_weight.0 , data=train, family = "binomial")
logit_preds <- as.data.frame(predict(mylogit, newdata=xtest, type="response"))
logit_preds$class <- ifelse(logit_preds[,1] >= .5, 1, 0)
logit_preds <- cbind(logit_preds, ytest)
logit_preds$result <- abs(logit_preds[,2] - logit_preds[,3])
logit_accurary <- 1 - sum(logit_preds$result)/length(ytest)
logit_accurary
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
## Set up full and null models
null_mod <- lm(formula = homeWin ~ 1, family = "binomial", data = full_matrix)
full_mod <- lm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + avg_scoreDiff +
avg_scoreDiff_home + avg_win_home + avg_scoreDiff_visit + avg_win_visit + log(home_rpi) +
log(away_rpi) + avg_GP + avg_GS+avg_MIN + avg_FG_made + avg_FG_attempted +
avg_FGpercent + avg_ThreeP_made + avg_ThreeP_attempted + avg_ThreePpercent + avg_FT_made +
avg_FT_attempted+ avg_FTpercent+ avg_OR+ avg_DR+ avg_REB+ avg_AST + avg_BLK+
avg_STL+ avg_PF +avg_TO+ avg_PTS, family="binomial", data=full_matrix)
## Stepwise model selection
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
importance(rf)
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
head(data)
## Set up full and null models
null_mod <- glm(formula = homeWin ~ 1, family = "binomial", data = full_matrix)
full_mod <- glm(homeWin ~ RPM_weight_0 + ORPM_weight_0 + DRPM_weight_0 + PER_weight_0 +
RPM_weight_1 + ORPM_weight_1 + DRPM_weight_1 + PER_weight_1 + avg_scoreDiff +
avg_scoreDiff_home + avg_win_home + avg_scoreDiff_visit + avg_win_visit + log(home_rpi) +
log(away_rpi) + avg_GP + avg_GS+avg_MIN + avg_FG_made + avg_FG_attempted +
avg_FGpercent + avg_ThreeP_made + avg_ThreeP_attempted + avg_ThreePpercent + avg_FT_made +
avg_FT_attempted+ avg_FTpercent+ avg_OR+ avg_DR+ avg_REB+ avg_AST + avg_BLK+
avg_STL+ avg_PF +avg_TO+ avg_PTS, family="binomial", data=full_matrix)
## Stepwise model selection
stepwise_mod <- step(null_mod, scope=list(lower=null_mod, upper=full_mod), direction="both")
names(stepwise_mod)
stepwise_mod$coeff
head(xtrain)
data <- mutate(data, home = 1)
data <- mutate(data, RPM_dif = RPM_weight.1 - RPM_weight.0)
data$homeWin <- ifelse(data$home_team_score > data$visit_team_score, 1, 0)
## Set up datasets ##
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010))
test = filter(data, game_year == 2011)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
train = filter(data, game_year %in% c(2008))
test = filter(data, game_year == 2009)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
train = filter(data, game_year %in% c(2008))
test = filter(data, game_year == 2009)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
train = filter(data, game_year %in% c(2008, 2009))
test = filter(data, game_year == 2010)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010))
test = filter(data, game_year == 2011)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011))
test = filter(data, game_year == 2012)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
years <- c(2008, 2009, 2010, 2011, 2012, 2013)
train = filter(data, game_year %in% c(2008, 2009, 2010, 2011, 2012))
test = filter(data, game_year == 2013)
xtest = test[,9:18]
ytest = test[,19]
xtrain = train[,9:18]
ytrain = train[,19]
## Naive Bayes
model <- naiveBayes(xtrain[,c(1,5) ], ytrain)
preds <- as.data.frame(predict(model, xtest, type = c("raw"), threshold = 0.001))
preds$class <- ifelse(preds[,2] > preds[,1], 1, 0)
preds <- cbind(preds, ytest)
preds$result <- abs(preds[,3] - preds[,4])
accuracy <- 1 - sum(preds$result)/length(ytest)
accuracy
