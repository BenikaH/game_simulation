\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{projections}
\citation{revolution}
\citation{nba_oracle}
\citation{data_mining}
\citation{nba_oracle}
\citation{bigrpm}
\citation{rpm}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Works}{1}{section.2}}
\citation{espn}
\citation{bball_ref}
\citation{rpm_data}
\citation{bball_ref}
\citation{rpm_data}
\citation{gitrepo}
\@writefile{toc}{\contentsline {section}{\numberline {3}Dataset}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Challenges for dataset preparation}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Data Sources}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Web Crawlers}{2}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Entity - Relationship graph for SQLite database. The database follows the third normal form to ensure there is no redundancy. Two main data sources of the dataset are ESPN and Basketball References websites. Lines between tables indicate the primary key - foreign key relationship between dataset entities.}}{3}{figure.1}}
\newlabel{fig:database}{{1}{3}{Entity - Relationship graph for SQLite database. The database follows the third normal form to ensure there is no redundancy. Two main data sources of the dataset are ESPN and Basketball References websites. Lines between tables indicate the primary key - foreign key relationship between dataset entities}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Merging Sources into One Database}{4}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Training and test datasets}{4}{subsection.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces A look at what our training and test datasets look like. The first four columns are features and the 5th column (indicating whether or not the home team won the game) is our label.}}{4}{table.1}}
\newlabel{table:matrix}{{1}{4}{A look at what our training and test datasets look like. The first four columns are features and the 5th column (indicating whether or not the home team won the game) is our label}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Left: visit team RPM against home team RPM with green dots meaning visit team wins and red dot meaning home team win. Right: A box plot of RPM. Y-axis represent the the RPM difference between home team and visit team. }}{5}{figure.2}}
\newlabel{feats}{{2}{5}{Left: visit team RPM against home team RPM with green dots meaning visit team wins and red dot meaning home team win. Right: A box plot of RPM. Y-axis represent the the RPM difference between home team and visit team}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Training the model and the test error}{5}{subsection.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces A look at how feature selection change the prediction accuracy.}}{5}{table.2}}
\newlabel{table:matrix}{{2}{5}{A look at how feature selection change the prediction accuracy}{table.2}{}}
\bibcite{nba_oracle}{1}
\bibcite{data_mining}{2}
\bibcite{rpm}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces This plot shows the test error for our different algorithms in all of our years. From this, we see that Naive Bayes and Logistic Regression gave us the best overall test error. For each testing year, we used all the previous years as training data.}}{6}{figure.3}}
\newlabel{fig:database}{{3}{6}{This plot shows the test error for our different algorithms in all of our years. From this, we see that Naive Bayes and Logistic Regression gave us the best overall test error. For each testing year, we used all the previous years as training data}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Simulation}{6}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{6}{section.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Results from simulating the 2013 NBA season 1000 times, using probabilities from our best Logistic regression model. The blue lines represent our confidence intervals whereas the Red lines represent the actual number of wins for each team. Our simulations trapped the true number of wins in 70 \% of our intervals.}}{7}{figure.4}}
\newlabel{fig:simulations}{{4}{7}{Results from simulating the 2013 NBA season 1000 times, using probabilities from our best Logistic regression model. The blue lines represent our confidence intervals whereas the Red lines represent the actual number of wins for each team. Our simulations trapped the true number of wins in 70 \% of our intervals}{figure.4}{}}
\bibcite{bigrpm}{4}
\bibcite{rpm_data}{5}
\bibcite{bball_ref}{6}
\bibcite{espn}{7}
\bibcite{gitrepo}{8}
\bibcite{projections}{9}
\bibcite{revolution}{10}
